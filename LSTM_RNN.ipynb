{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ES6C6WvL3pd",
        "outputId": "285e7f40-58c0-4ff5-9a05-b69d05021330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Data COllection\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "import pandas as pd\n",
        "\n",
        "# Loading the dataset\n",
        "\n",
        "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "\n",
        "# Save in the file\n",
        "\n",
        "with open('hamlet.txt', 'w') as file:\n",
        "    file.write(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "# import tensorflow as tf\n",
        "# import keras\n",
        "# import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "with open('hamlet.txt', 'r') as file:\n",
        "    text = file.read().lower()\n",
        "\n",
        "# Tokenize the datset\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJUPCR7zMFuO",
        "outputId": "8ca051b9-29e5-4a91-e76b-d662ff05d8ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4818"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create input sequences\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for line in text.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "b-EnbXeGMFq4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfX5LX0FMFom",
        "outputId": "b9159d2e-f919-4b25-9d6b-5516f9c6743d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 687],\n",
              " [1, 687, 4],\n",
              " [1, 687, 4, 45],\n",
              " [1, 687, 4, 45, 41],\n",
              " [1, 687, 4, 45, 41, 1886]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad Sequence\n",
        "import numpy as np\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "max_sequence_len\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPdOVVuWMFmR",
        "outputId": "27a9f8e4-1e2f-430a-9280-b191ac034426"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I2tKGaZMFjr",
        "outputId": "e3496670-0c80-48f1-c7fa-8547d2e7a2a5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    1,  687],\n",
              "       [   0,    0,    0, ...,    1,  687,    4],\n",
              "       [   0,    0,    0, ...,  687,    4,   45],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4,   45, 1047],\n",
              "       [   0,    0,    0, ...,   45, 1047,    4],\n",
              "       [   0,    0,    0, ..., 1047,    4,  193]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "-8WH4zPsMFhj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfkgkfzdMFfR",
        "outputId": "187b1faa-0fda-41c0-c4fa-c0a05c564b8f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    0,    1],\n",
              "       [   0,    0,    0, ...,    0,    1,  687],\n",
              "       [   0,    0,    0, ...,    1,  687,    4],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  687,    4,   45],\n",
              "       [   0,    0,    0, ...,    4,   45, 1047],\n",
              "       [   0,    0,    0, ...,   45, 1047,    4]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf1ukslMMFcs",
        "outputId": "91d6a140-98f7-440e-e7f3-355702e7cdad"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 687,    4,   45, ..., 1047,    4,  193], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y =tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2Jy3JQzMFaL",
        "outputId": "0e78e3ad-d452-4966-b10c-de107c84d568"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset in train test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "rBq-LgMNMFXt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_words)\n",
        "print(max_sequence_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LHNoOPtU8si",
        "outputId": "3f0c740c-26d7-46b6-a908-f931ec41a8fc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4818\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training our LSTM model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length = max_sequence_len))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compiling the model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, max_sequence_len))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "J6ZkDiEyRpVW",
        "outputId": "3b6ac627-b6d2-4440-8ed3-b8021ada365c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m481,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │         \u001b[38;5;34m150,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m100,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4818\u001b[0m)                │         \u001b[38;5;34m486,618\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">481,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4818</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">486,618</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,219,418\u001b[0m (4.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,219,418</span> (4.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,219,418\u001b[0m (4.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,219,418</span> (4.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50,validation_data = (X_test, y_test),verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpvq2W03RpRv",
        "outputId": "5bfe3248-183d-4b47-8b53-af849b1f4e8a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 64ms/step - accuracy: 0.0303 - loss: 7.1563 - val_accuracy: 0.0336 - val_loss: 6.6984\n",
            "Epoch 2/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.0384 - loss: 6.4750 - val_accuracy: 0.0410 - val_loss: 6.7622\n",
            "Epoch 3/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 62ms/step - accuracy: 0.0428 - loss: 6.3602 - val_accuracy: 0.0470 - val_loss: 6.7892\n",
            "Epoch 4/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.0531 - loss: 6.1624 - val_accuracy: 0.0538 - val_loss: 6.8077\n",
            "Epoch 5/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.0534 - loss: 5.9975 - val_accuracy: 0.0579 - val_loss: 6.8707\n",
            "Epoch 6/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 61ms/step - accuracy: 0.0622 - loss: 5.8638 - val_accuracy: 0.0593 - val_loss: 6.9061\n",
            "Epoch 7/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 62ms/step - accuracy: 0.0703 - loss: 5.7294 - val_accuracy: 0.0637 - val_loss: 6.9759\n",
            "Epoch 8/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.0792 - loss: 5.6017 - val_accuracy: 0.0696 - val_loss: 7.0421\n",
            "Epoch 9/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.0866 - loss: 5.4635 - val_accuracy: 0.0659 - val_loss: 7.1064\n",
            "Epoch 10/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.0956 - loss: 5.2986 - val_accuracy: 0.0664 - val_loss: 7.2041\n",
            "Epoch 11/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 59ms/step - accuracy: 0.1054 - loss: 5.1521 - val_accuracy: 0.0639 - val_loss: 7.2843\n",
            "Epoch 12/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 59ms/step - accuracy: 0.1027 - loss: 5.0658 - val_accuracy: 0.0684 - val_loss: 7.3225\n",
            "Epoch 13/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.1081 - loss: 4.9337 - val_accuracy: 0.0663 - val_loss: 7.4651\n",
            "Epoch 14/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 62ms/step - accuracy: 0.1125 - loss: 4.8295 - val_accuracy: 0.0664 - val_loss: 7.5544\n",
            "Epoch 15/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 60ms/step - accuracy: 0.1235 - loss: 4.6980 - val_accuracy: 0.0647 - val_loss: 7.6607\n",
            "Epoch 16/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.1277 - loss: 4.5540 - val_accuracy: 0.0645 - val_loss: 7.8166\n",
            "Epoch 17/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.1351 - loss: 4.4261 - val_accuracy: 0.0631 - val_loss: 7.9235\n",
            "Epoch 18/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.1419 - loss: 4.3558 - val_accuracy: 0.0614 - val_loss: 8.0579\n",
            "Epoch 19/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.1615 - loss: 4.2162 - val_accuracy: 0.0651 - val_loss: 8.1837\n",
            "Epoch 20/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.1713 - loss: 4.0966 - val_accuracy: 0.0626 - val_loss: 8.3240\n",
            "Epoch 21/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 61ms/step - accuracy: 0.1828 - loss: 4.0279 - val_accuracy: 0.0647 - val_loss: 8.4625\n",
            "Epoch 22/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 60ms/step - accuracy: 0.2094 - loss: 3.8900 - val_accuracy: 0.0616 - val_loss: 8.5818\n",
            "Epoch 23/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 61ms/step - accuracy: 0.2241 - loss: 3.7812 - val_accuracy: 0.0587 - val_loss: 8.7372\n",
            "Epoch 24/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 62ms/step - accuracy: 0.2337 - loss: 3.7280 - val_accuracy: 0.0624 - val_loss: 8.8659\n",
            "Epoch 25/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 62ms/step - accuracy: 0.2477 - loss: 3.6294 - val_accuracy: 0.0595 - val_loss: 9.0024\n",
            "Epoch 26/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 63ms/step - accuracy: 0.2640 - loss: 3.5615 - val_accuracy: 0.0602 - val_loss: 9.1096\n",
            "Epoch 27/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.2818 - loss: 3.4704 - val_accuracy: 0.0561 - val_loss: 9.2231\n",
            "Epoch 28/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.2836 - loss: 3.4251 - val_accuracy: 0.0577 - val_loss: 9.3382\n",
            "Epoch 29/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 65ms/step - accuracy: 0.2996 - loss: 3.3468 - val_accuracy: 0.0583 - val_loss: 9.4743\n",
            "Epoch 30/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 61ms/step - accuracy: 0.3127 - loss: 3.2813 - val_accuracy: 0.0581 - val_loss: 9.5706\n",
            "Epoch 31/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 62ms/step - accuracy: 0.3192 - loss: 3.2053 - val_accuracy: 0.0569 - val_loss: 9.6860\n",
            "Epoch 32/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 61ms/step - accuracy: 0.3343 - loss: 3.1509 - val_accuracy: 0.0563 - val_loss: 9.7869\n",
            "Epoch 33/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.3497 - loss: 3.0860 - val_accuracy: 0.0552 - val_loss: 9.8860\n",
            "Epoch 34/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.3605 - loss: 3.0351 - val_accuracy: 0.0577 - val_loss: 10.0004\n",
            "Epoch 35/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.3588 - loss: 2.9869 - val_accuracy: 0.0544 - val_loss: 10.0732\n",
            "Epoch 36/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.3721 - loss: 2.9318 - val_accuracy: 0.0542 - val_loss: 10.1994\n",
            "Epoch 37/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.3843 - loss: 2.8728 - val_accuracy: 0.0560 - val_loss: 10.2645\n",
            "Epoch 38/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.3867 - loss: 2.8425 - val_accuracy: 0.0544 - val_loss: 10.3379\n",
            "Epoch 39/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 61ms/step - accuracy: 0.3965 - loss: 2.7983 - val_accuracy: 0.0548 - val_loss: 10.4111\n",
            "Epoch 40/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 65ms/step - accuracy: 0.4073 - loss: 2.7473 - val_accuracy: 0.0546 - val_loss: 10.5198\n",
            "Epoch 41/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 63ms/step - accuracy: 0.4170 - loss: 2.6939 - val_accuracy: 0.0552 - val_loss: 10.5920\n",
            "Epoch 42/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.4142 - loss: 2.6796 - val_accuracy: 0.0532 - val_loss: 10.6499\n",
            "Epoch 43/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.4290 - loss: 2.6293 - val_accuracy: 0.0499 - val_loss: 10.7429\n",
            "Epoch 44/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.4377 - loss: 2.5923 - val_accuracy: 0.0519 - val_loss: 10.8240\n",
            "Epoch 45/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.4506 - loss: 2.5393 - val_accuracy: 0.0523 - val_loss: 10.8723\n",
            "Epoch 46/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 63ms/step - accuracy: 0.4496 - loss: 2.5009 - val_accuracy: 0.0528 - val_loss: 10.9654\n",
            "Epoch 47/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 65ms/step - accuracy: 0.4520 - loss: 2.4866 - val_accuracy: 0.0493 - val_loss: 10.9959\n",
            "Epoch 48/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.4696 - loss: 2.4251 - val_accuracy: 0.0503 - val_loss: 11.0912\n",
            "Epoch 49/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 62ms/step - accuracy: 0.4743 - loss: 2.4043 - val_accuracy: 0.0527 - val_loss: 11.1742\n",
            "Epoch 50/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 60ms/step - accuracy: 0.4781 - loss: 2.3660 - val_accuracy: 0.0523 - val_loss: 11.2034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "\n",
        "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
        "  token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "  if len(token_list) >= max_sequence_len:\n",
        "    token_list= token_list[-(max_sequence_len-1):]\n",
        "\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
        "  predicted = model.predict(token_list, verbose = 0)\n",
        "  predicted_word_index = np.argmax(predicted, axis =1)\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "      return word\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "uE7jpvXjRpPH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = 'To be or not to be'\n",
        "print(f'Input Text : {input_text}')\n",
        "max_sequence_len = model.input_shape[1] +1\n",
        "next_word = predict_next_word(model, tokenizer, input_text, max_sequence_len)\n",
        "print(f'Next Word : {next_word}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7HsgeY7RpLd",
        "outputId": "2dddfd98-2451-4455-95c9-0b2414ad1408"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text : To be or not to be\n",
            "Next Word : buried\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.save(\"next_word_LSTM.h5\")\n",
        "\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIQztx0iRpHj",
        "outputId": "59c45f96-3e02-414b-a150-40f2a3ef1e2f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared"
      ],
      "metadata": {
        "id": "-VEycMl9Ro8M"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"Streamlit on Colab with Cloudflare\")\n",
        "st.write(\"If you're seeing this, the app is working!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA2fgt3URo52",
        "outputId": "5e7fb710-214f-4ace-89ab-b8b899cff8e7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &> logs.txt &\n",
        "!./cloudflared tunnel --url http://localhost:8501 --log-level debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkSl086Cmk8L",
        "outputId": "8fa4980e-95b4-4352-933b-03bf0d0c191f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./cloudflared: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vA_hdAAXmk42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F6MSvb5_mk14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B1H9CNOamkzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}